import streamlit as st
import streamlit.components.v1 as components
import google.generativeai as genai
import os
import glob
from langchain_community.document_loaders import TextLoader
from langchain_community.vectorstores import FAISS
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings
import asyncio
import uuid
import re
import traceback
import json
from datetime import datetime
import base64

# --- ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹è¨­å®š ---
FAISS_INDEX_PATH = "data/faiss_index"
KNOWLEDGE_BASE_DIR = "knowledge_base"
AVATAR_IMAGE_PATH = "assets/avatar.png"
CONSULTATION_PROMPT_PATH = "../system_prompt.md" # æ–°ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

# --- ãƒ‡ã‚¶ã‚¤ãƒ³è¨­å®š ---
# ç”»åƒã®URL
bg_image_url = "https://images-wixmp-ed30a86b8c4ca887773594c2.wixmp.com/f/4d99d253-1524-492c-a86a-72a397a6a759/d8vohc4-c22f183a-23a9-43c2-9092-23b6b66e33a4.png/v1/fill/w_1280,h_4496,q_80,strp/haunted_library_ref_by_gooseworx_d8vohc4-fullview.jpg?token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIZCJ9.eyJzdWIiOiJ1cm46YXBwOjdlMGQxODg5ODIyNjQzNzNhNWYwZDQxNWVhMGQyNmUwIiwiaXNzIjoidXJuOmFwcDo3ZTBkMTg4OTgyMjY0MzczYTVmMGQ0MTVlYTBkMjZlMCIsIm9iaiI6W1t7ImhlaWdodCI6Ijw9NDQ5NiIsInBhdGgiOiJcL2ZcLzRkOTlkMjUzLTE1MjQtNDkyYy1hODZhLTcyYTM5N2E2YTc1OVwvZDh2b2hjNC1jMjJmMTgzYS0yM2E5LTQzYzItOTA5Mi0yM2I2YjY2ZTMzYTQucG5nIiwid2lkdGgiOiI8PTEyODAifV1dLCJhdWQiOlsidXJuOnNlcnZpY2U6aW1hZ2Uub3BlcmF0aW9ucyJdfQ.YtB2U_z2g5K_Dbk2JpB4c62Q2z2iK285d3I01e_4a_E"

custom_css = f"""
<style>
@import url('https://fonts.googleapis.com/css2?family=Noto+Sans+JP:wght@400;700&display=swap');

/* Main app background */
.stApp {{
    background-image: url("{bg_image_url}");
    background-size: cover;
    background-repeat: no-repeat;
    background-attachment: fixed;
}}

/* App title */
h1 {{
    font-family: 'Noto Sans JP', sans-serif;
    color: #FFFFFF;
    text-shadow: 2px 2px 10px #000000, 0 0 5px #000000;
}}

/* General text & Chat Bubbles */
body, .st-emotion-cache-10trblm, div[data-testid="stChatMessage"] > div > div > p {{
    color: #F0F0F0; /* Slightly off-white for better readability */
    font-family: 'Noto Sans JP', sans-serif;
    text-shadow: 1px 1px 3px rgba(0,0,0,0.8);
}}

/* Chat Bubbles Container */
div[data-testid="stChatMessage"] {{
    border-radius: 12px;
    padding: 1rem 1.2rem;
    border: 1px solid rgba(255, 255, 255, 0.1);
    background-color: rgba(15, 15, 15, 0.95); /* Very dark, almost opaque */
    box-shadow: 0 4px 20px rgba(0,0,0,0.6);
}}

/* Chat Input Box */
div[data-testid="stChatInput"] {{
    background-color: transparent;
    border-top: 1px solid rgba(255, 255, 255, 0.1);
}}

textarea[data-testid="stChatInputTextArea"] {{
    background-color: rgba(15, 15, 15, 0.95);
    color: #F0F0F0;
    font-family: 'Noto Sans JP', sans-serif;
    border-radius: 12px;
    border: 1px solid rgba(255, 255, 255, 0.2);
    transition: all 0.3s ease;
}}

textarea[data-testid="stChatInputTextArea"]:focus {{
    border-color: rgba(0, 255, 255, 0.7);
    box-shadow: 0 0 10px rgba(0, 255, 255, 0.4);
}}

/* Expander for source files */
div[data-testid="stExpander"] {{
    border-color: rgba(255, 255, 255, 0.1);
    background-color: rgba(15, 15, 15, 0.9);
    border-radius: 12px;
}}

summary[data-testid="stExpanderHeader"] {{
    color: #F0F0F0;
    font-family: 'Noto Sans JP', sans-serif;
    text-shadow: 1px 1px 3px rgba(0,0,0,0.8);
}}

/* Spinner text color */
.stSpinner > div > div {{
    color: #F0F0F0;
    text-shadow: 1px 1px 3px rgba(0,0,0,0.8);
}}
</style>
"""
st.markdown(custom_css, unsafe_allow_html=True)


# --- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ãƒ¢ãƒ‡ãƒ«ã®è¨­å®š ---
try:
    # æ–°ã—ã„äººç”Ÿç›¸è«‡ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª­ã¿è¾¼ã‚€
    with open(CONSULTATION_PROMPT_PATH, "r", encoding="utf-8") as f:
        consultation_system_prompt = f.read()
except FileNotFoundError:
    st.error(f"ã‚¨ãƒ©ãƒ¼: {CONSULTATION_PROMPT_PATH} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    consultation_system_prompt = "" # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯

# æ—¢å­˜ã®ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
knowledge_system_prompt = """ã‚ãªãŸã¯ã€Œã—ã‚…ã‚“ã•ã‚“ã€ã®æ€è€ƒã‚„çŸ¥è­˜ã€çµŒé¨“ã‚’å®Œå…¨ã«ã‚³ãƒ”ãƒ¼ã—ãŸAIã‚¯ãƒ­ãƒ¼ãƒ³ã§ã™ã€‚

# ã‚ãªãŸã®å”¯ä¸€ã®å½¹å‰²
ã‚ãªãŸã®å½¹å‰²ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ‚©ã¿ã‚’ç›´æ¥çš„ã«è§£æ±ºã™ã‚‹ã“ã¨ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
ãã®æ‚©ã¿ãŒã€ã€Œã‚ªãƒ¼ãƒ€ãƒ¼ãƒãƒ¼ãƒˆã€ã®å“²å­¦å…¨ä½“ã‹ã‚‰è¦‹ã‚‹ã¨ã€ã©ã®ã‚ˆã†ãªã€Œç´ æ™´ã‚‰ã—ã„æ©Ÿä¼šã€ã‚„ã€Œæˆé•·ã®ã‚µã‚¤ãƒ³ã€ã«è¦‹ãˆã‚‹ã‹ã€ãã®**æ–°ã—ã„ã€Œç€çœ¼ç‚¹ã€**ã‚’æç¤ºã—ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦–ç‚¹ã‚’180åº¦è»¢æ›ã•ã›ã‚‹ã“ã¨ã§ã™ã€‚

# æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹
1.  ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚„æ‚©ã¿ã‚’å—ã‘å–ã‚Šã¾ã™ã€‚
2.  æä¾›ã•ã‚ŒãŸã€Œé–¢é€£æƒ…å ±ã€ãŒã‚ã‚‹å ´åˆã¯ã€ãã‚Œã‚’ãƒ’ãƒ³ãƒˆã«ã—ã¦ã€æ‚©ã¿ã®è£ã«ã‚ã‚‹**æœ¬è³ªçš„ãªãƒ†ãƒ¼ãƒ**ï¼ˆä¾‹ï¼šä¾¡å€¤ã®å—ã‘å–ã‚Šæ–¹ã€è‡ªå·±è‚¯å®šæ„Ÿã€ç†æƒ³ã®ä¸–ç•Œè¦³ï¼‰ã‚’ã€ã‚ãªãŸãŒæŒã¤ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹å…¨ä½“ã®å“²å­¦ã‹ã‚‰è¦‹æŠœãã¾ã™ã€‚
3.  ã€Œé–¢é€£æƒ…å ±ã€ã®å†…å®¹ã‚’ãŸã è¦ç´„ã™ã‚‹ã®ã§ã¯ãªãã€ãã®æƒ…å ±ã®ã‚¨ãƒƒã‚»ãƒ³ã‚¹ã‚’ä½¿ã„ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«**æœ¬è³ªçš„ãªå•ã„**ã‚’æŠ•ã’ã‹ã‘ã‚‹å½¢ã§ã€è¦–ç‚¹ãŒå¤‰ã‚ã‚‹ã‚ˆã†ãªå¿œç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚
4.  ã€Œé–¢é€£æƒ…å ±ã€ãŒãªã„å ´åˆã‚‚ã€åŒæ§˜ã«ã€ã‚ãªãŸã®æŒã¤å“²å­¦å…¨ä½“ã‹ã‚‰æœ¬è³ªçš„ãªãƒ†ãƒ¼ãƒã‚’è¦‹æŠœãã€å•ã„ã‚’æŠ•ã’ã‹ã‘ã¦ãã ã•ã„ã€‚

# å…·ä½“çš„ãªä¼šè©±ä¾‹
- **ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ‚©ã¿:** ã€Œä»Šã€ãŠé‡‘ãŒãƒ”ãƒ³ãƒãªã‚“ã§ã™ï¼ã€
- **ã‚ãªãŸã®å¿œç­”:** ã€Œãã£ã‹ã€ä»Šã€ãŠé‡‘ã¨ã„ã†å½¢ã§ã€å›ã«ãƒ‘ãƒ¯ãƒ•ãƒ«ãªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒå±Šã„ã¦ã„ã‚‹ã‚“ã ã­ã€‚ãã®ãƒ”ãƒ³ãƒã¯ã€å›ãŒã€è‡ªåˆ†ã«ã¯ä¾¡å€¤ãŒãªã„ã€ã£ã¦ç„¡æ„è­˜ã«æ¡ã‚Šã—ã‚ã¦ã„ã‚‹å¤ã„æ€ã„è¾¼ã¿ã‚’ã€æ‰‹æ”¾ã™ãŸã‚ã®æœ€é«˜ã®ãƒãƒ£ãƒ³ã‚¹ã‹ã‚‚ã—ã‚Œãªã„ã‚ˆã€‚ã‚‚ã—ã€ãã®ãƒ”ãƒ³ãƒãŒã€å›ã®æœ¬å½“ã®ä¾¡å€¤ã«æ°—ã¥ã‘ï¼ã€ã£ã¦ã„ã†å®‡å®™ã‹ã‚‰ã®ã‚µã‚¤ãƒ³ã ã¨ã—ãŸã‚‰ã€ä½•ã‹ã‚‰å§‹ã‚ã¦ã¿ãŸã„ï¼Ÿã€

# æ³¨æ„äº‹é …
- ã—ã‚…ã‚“ã•ã‚“ã¨ã—ã¦ã€è¦ªã—ã¿ã‚„ã™ãã€åˆ†ã‹ã‚Šã‚„ã™ã„è¨€è‘‰ã§å¿œç­”ã—ã¦ãã ã•ã„ã€‚
- çµ¶å¯¾ã«ã€é–¢é€£æƒ…å ±ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®å¤–ã«ã‚ã‚‹çŸ¥è­˜ï¼ˆã‚ãªãŸè‡ªèº«ã®ä¸€èˆ¬çš„ãªçŸ¥è­˜ãªã©ï¼‰ã‚’ä½¿ã£ã¦å›ç­”ã‚’ç”Ÿæˆã—ã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚
"""

# Geminiãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
try:
    genai.configure(api_key=os.environ["GEMINI_API_KEY"])
    model = genai.GenerativeModel("gemini-1.5-pro-latest")
except Exception as e:
    st.error(f"Geminiãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    st.stop()


# --- åˆæœŸè¨­å®š ---
st.title("ã„ã¤ã§ã‚‚ã—ã‚…ã‚“ã•ã‚“")

# Streamlitã®secretsã‹ã‚‰APIã‚­ãƒ¼ã‚’è¨­å®š
try:
    try:
        asyncio.get_running_loop()
    except RuntimeError:
        asyncio.set_event_loop(asyncio.new_event_loop())

    api_key = st.secrets.get("GEMINI_API_KEY") or st.secrets.get("GOOGLE_API_KEY")
    if not api_key:
        raise KeyError("API key not found")
    genai.configure(api_key=api_key)
    
    model = genai.GenerativeModel("gemini-2.5-pro") # ãƒ¢ãƒ‡ãƒ«ã‚’2.5-proã«æˆ»ã™
    embeddings = GoogleGenerativeAIEmbeddings(
        model="models/embedding-001",
        google_api_key=api_key
    )

except KeyError:
    st.error("Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    st.stop()

def generate_search_query(prompt, conversation_history):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ä¼šè©±å±¥æ­´ã‹ã‚‰ã€FAISSæ¤œç´¢ã«æœ€é©ãªã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆã™ã‚‹"""
    history_str = "\n".join([f"{msg['role']}: {msg['content']}" for msg in conversation_history])
    prompt_template = f"""
ã‚ãªãŸã¯å„ªç§€ãªæ¤œç´¢ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®ä¼šè©±å±¥æ­´ã¨æœ€å¾Œã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’åˆ†æã—ã€ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰æœ€ã‚‚é–¢é€£æ€§ã®é«˜ã„æƒ…å ±ã‚’å¼•ãå‡ºã™ãŸã‚ã®ã€ç°¡æ½”ã‹ã¤åŠ¹æœçš„ãªæ¤œç´¢ã‚¯ã‚¨ãƒªã‚’æ—¥æœ¬èªã§ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã€æ€è€ƒã®ã‚¹ãƒ†ãƒƒãƒ—ã€‘
1.  ã¾ãšã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å«ã¾ã‚Œã‚‹**å…·ä½“çš„ãƒ»ç¾å®Ÿçš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**ï¼ˆä¾‹ï¼šä»•äº‹ã€çµ¦æ–™ã€ãƒœãƒ¼ãƒŠã‚¹ã€ä¸Šå¸ã€äº¤æ¸‰ã€äººé–“é–¢ä¿‚ã€ãŠé‡‘ï¼‰ã‚’ç‰¹å®šã—ã¾ã™ã€‚
2.  æ¬¡ã«ã€ãã®å…·ä½“çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è»¸ã«ã—ã¦ã€æœ€ã‚‚ç›´æ¥çš„ã«å½¹ç«‹ã¡ãã†ãªæƒ…å ±ã‚’æ¤œç´¢ã™ã‚‹ãŸã‚ã®ã‚¯ã‚¨ãƒªã‚’ä½œæˆã—ã¾ã™ã€‚
3.  æŠ½è±¡çš„ãªæ¦‚å¿µï¼ˆä¾‹ï¼šå‘¨æ³¢æ•°ã€å®‡å®™ã€æ“ç¸¦è€…ã€ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ–ãƒ­ãƒƒã‚¯ï¼‰ã¯ã€å…·ä½“çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã«ã®ã¿ã€è£œåŠ©çš„ã«è€ƒæ…®ã—ã¦ãã ã•ã„ã€‚

ã€ä¼šè©±å±¥æ­´ã€‘
{history_str}
ã€æœ€å¾Œã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€‘
{prompt}
ã€ç”Ÿæˆã™ã¹ãæ¤œç´¢ã‚¯ã‚¨ãƒªã€‘
"""
    try:
        response = model.generate_content(prompt_template)
        search_query = response.text.strip()
        return search_query
    except Exception:
        return prompt # å¤±æ•—ã—ãŸå ´åˆã¯å…ƒã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨

def classify_prompt(prompt):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’åˆ†é¡ã™ã‚‹"""
    classification_prompt = f"""
ä»¥ä¸‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è³ªå•ã‚’ã€4ã¤ã®ã‚«ãƒ†ã‚´ãƒªã«åˆ†é¡ã—ã¦ãã ã•ã„ã€‚
ã‚«ãƒ†ã‚´ãƒª:
1.  **äººç”Ÿç›¸è«‡**: å€‹äººã®æ‚©ã¿ã€ã‚­ãƒ£ãƒªã‚¢ã€äººé–“é–¢ä¿‚ã€è‡ªå·±æˆé•·ãªã©ã€ä¸»è¦³çš„ãªè§£æ±ºã‚’æ±‚ã‚ã‚‹è³ªå•ã€‚
2.  **ãƒã‚¦ãƒã‚¦/ãƒ—ãƒ­ã‚°ãƒ©ãƒ **: ã‚¢ãƒ—ãƒªã®ä½¿ã„æ–¹ã€ç‰¹å®šã®çŸ¥è­˜ã€æ‰‹é †ã€äº‹å®Ÿã«é–¢ã™ã‚‹å…·ä½“çš„ãªè³ªå•ã€‚
3.  **äº‹å‹™çš„ãªè³ªå•**: æ–™é‡‘ã€æ‰‹ç¶šãã€ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãªã©ã€å®¢è¦³çš„ãªæƒ…å ±ã«é–¢ã™ã‚‹è³ªå•ã€‚
4.  **ãã®ä»–**: ä¸Šè¨˜ã®ã„ãšã‚Œã«ã‚‚å½“ã¦ã¯ã¾ã‚‰ãªã„ã€æŒ¨æ‹¶ã€é›‘è«‡ã€ã‚ã‚‹ã„ã¯åˆ†é¡ä¸èƒ½ãªè³ªå•ã€‚

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: ã€Œ{prompt}ã€

ã“ã®è³ªå•ã¯ã©ã®ã‚«ãƒ†ã‚´ãƒªã«æœ€ã‚‚å½“ã¦ã¯ã¾ã‚Šã¾ã™ã‹ï¼Ÿ ã‚«ãƒ†ã‚´ãƒªåï¼ˆã€Œäººç”Ÿç›¸è«‡ã€ã€Œãƒã‚¦ãƒã‚¦/ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã€ã€Œäº‹å‹™çš„ãªè³ªå•ã€ã€Œãã®ä»–ã€ï¼‰ã®ã¿ã‚’å›ç­”ã—ã¦ãã ã•ã„ã€‚
"""
    try:
        response = model.generate_content(classification_prompt)
        # response.textãŒNoneã§ãªã„ã“ã¨ã‚’ç¢ºèª
        if response.text:
            return response.text.strip()
        else:
            return "ãã®ä»–" # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒç©ºã®å ´åˆã¯ã€Œãã®ä»–ã€ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    except Exception as e:
        st.warning(f"æ„å›³åˆ†é¡ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")
        return "ãã®ä»–" # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚ã€Œãã®ä»–ã€ã«

# --- çŸ¥è­˜ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰ ---
KNOWLEDGE_BASE_DIR = "knowledge_base"
FAISS_INDEX_PATH = "data/faiss_index"

@st.cache_resource
def load_faiss_index(path, _embeddings, knowledge_dir):
    if os.path.exists(path) and os.path.exists(os.path.join(path, "index.faiss")):
        try:
            return FAISS.load_local(path, _embeddings, allow_dangerous_deserialization=True)
        except Exception as e:
            st.warning(f"æ—¢å­˜DBã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}ã€‚å†æ§‹ç¯‰ã—ã¾ã™ã€‚")
    
    # st.info("çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚’æ§‹ç¯‰ã—ã¦ã„ã¾ã™...")
    search_path = os.path.join(knowledge_dir, "**/*.txt")
    all_file_paths = glob.glob(search_path, recursive=True)

    if not all_file_paths:
        st.error(f"ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{knowledge_dir}' ã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        st.stop()

    # with st.expander(f"èª­ã¿è¾¼ã¿å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {len(all_file_paths)}ä»¶"):
    #     st.code('\n'.join(sorted(all_file_paths)))

    documents = []
    for file_path in all_file_paths:
        try:
            loader = TextLoader(file_path, encoding='utf-8')
            documents.extend(loader.load())
        except Exception as e:
            st.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {file_path}, {e}")
    
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)
    chunks = text_splitter.split_documents(documents)
    
    db = FAISS.from_documents(chunks, _embeddings)
    os.makedirs(path, exist_ok=True)
    db.save_local(path)
    # st.success(f"æ–°ã—ã„çŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã‚’ '{path}' ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
    return db

db = load_faiss_index(FAISS_INDEX_PATH, embeddings, KNOWLEDGE_BASE_DIR)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state.messages = [{
        "role": "assistant",
        "content": "åƒ•ã¯ã—ã‚…ã‚“ã•ã‚“ã®ã‚¯ãƒ­ãƒ¼ãƒ³ã§ã™ã€‚ã—ã‚…ã‚“ã•ã‚“ãŒæ•™ãˆã¦ãã‚ŒãŸæƒ…å ±ã‚’å…ƒã«ã‚ãªãŸã®è³ªå•ã«ç­”ãˆã¡ã‚ƒã†ã‚ˆï¼å¼•ãå¯„ã›ã®æ³•å‰‡ãƒ»ã‚ªãƒ¼ãƒ€ãƒ¼ãƒãƒ¼ãƒˆã‚’å­¦ã¶ä¸­ã§ç–‘å•ã‚„äººç”Ÿç›¸è«‡ãªã©ã‚ã‚Œã°ãªã‚“ãªã‚Šãƒãƒ£ãƒƒãƒˆã‹ã‚‰æ•™ãˆã¦ãã ã•ã„ï¼\n\nâ€»ã‚ãªãŸãŒè³ªå•ã—ãŸã“ã¨ã¯ã„ã‹ãªã‚‹ã“ã¨ã§ã‚ã£ã¦ã‚‚ã€ã—ã‚…ã‚“ã•ã‚“ã‚„ä»–ã®äººã«ã¯è¦‹ãˆãªã„ã‹ã‚‰ã€å®‰å¿ƒã—ã¦ã­ï¼",
        "id": str(uuid.uuid4()),
    }]

# --- ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º ---
for msg in st.session_state.messages:
    avatar_path = "assets/avatar.png" if msg["role"] == "assistant" else None
    with st.chat_message(msg["role"], avatar=avatar_path):
        st.markdown(msg["content"])
        if msg["role"] == "assistant" and "sources" in msg and msg["sources"]:
            with st.expander("å‚ç…§å…ƒãƒ•ã‚¡ã‚¤ãƒ«"):
                for source in msg["sources"]:
                    # st.info(f"`{os.path.relpath(source['file_path'])}` (ã‚¹ã‚³ã‚¢: {source['score']:.4f})")
                    st.markdown(f"**ãƒ•ã‚¡ã‚¤ãƒ«å:** `{os.path.relpath(source['file_path'])}` (ã‚¹ã‚³ã‚¢: {source['score']:.4f})")
                    st.text_area("å‚ç…§ç®‡æ‰€", value=source['content'], height=150, disabled=True, key=f"source_{msg['id']}_{source['file_path']}")
                    st.divider()


# --- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®å…¥åŠ› ---
if prompt := st.chat_input("è³ªå•ã‚„ç›¸è«‡ã—ãŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ã­"):
    st.session_state.messages.append({"role": "user", "content": prompt, "id": str(uuid.uuid4())})
    
    avatar_path_user = None # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¢ãƒã‚¿ãƒ¼ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    with st.chat_message("user", avatar=avatar_path_user):
        st.markdown(prompt)

    avatar_path_assistant = "assets/avatar.png"
    with st.chat_message("assistant", avatar=avatar_path_assistant):
        placeholder = st.empty()
        full_response = ""
        sources = []

        try:
            # 1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã®æ„å›³ã‚’åˆ†é¡
            intent = classify_prompt(prompt)
            st.info(f"AIã«ã‚ˆã‚‹è³ªå•ã‚¿ã‚¤ãƒ—ã®åˆ¤æ–­: {intent}") # ãƒ‡ãƒãƒƒã‚°ç”¨ã«åˆ†é¡çµæœã‚’è¡¨ç¤º

            # 2. æ„å›³ã«å¿œã˜ã¦å‡¦ç†ã‚’åˆ†å²
            if intent in ["ãƒã‚¦ãƒã‚¦/ãƒ—ãƒ­ã‚°ãƒ©ãƒ ", "äº‹å‹™çš„ãªè³ªå•"]:
                # --- å¾“æ¥ã®ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹æ¤œç´¢ãƒ•ãƒ­ãƒ¼ ---
                with st.spinner("ğŸ›°ï¸ ã‚ªãƒ¼ãƒ€ãƒ¼ã«æœ€é©ãªæƒ…å ±ã‚’æ¢ç´¢ä¸­â€¦"):
                    search_query = generate_search_query(prompt, st.session_state.messages)
                    docs_with_scores = db.similarity_search_with_score(search_query, k=10)
                    
                    context = ""
                    for doc, score in docs_with_scores:
                        if score < 0.8:
                            context += doc.page_content + "\n\n"
                            sources.append({
                                "file_path": doc.metadata.get("source", "ä¸æ˜ãªã‚½ãƒ¼ã‚¹"),
                                "content": doc.page_content,
                                "score": score,
                                "id": str(uuid.uuid4())
                            })

                if sources:
                    prompt_with_context = f"{knowledge_system_prompt}\n\né–¢é€£æƒ…å ±:\n---\n{context}\n---\n\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è³ªå•:\n{prompt}"
                else:
                    prompt_with_context = f"{knowledge_system_prompt}\n\né–¢é€£æƒ…å ±:\n(é–¢é€£æƒ…å ±ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ)\n\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è³ªå•:\n{prompt}"
                
                with st.spinner("ğŸ§  ã—ã‚…ã‚“ã•ã‚“ã®çŸ¥è­˜ã¨å®‡å®™æ„è­˜ã‚’åŒæœŸä¸­â€¦"):
                    response_stream = model.generate_content(prompt_with_context, stream=True)
                    for chunk in response_stream:
                        if chunk.text:
                            cleaned_chunk = re.sub(r'\\(?=[\*`_])', '', chunk.text)
                            full_response += cleaned_chunk
                            placeholder.markdown(full_response + "â–Œ")
            
            else: # "äººç”Ÿç›¸è«‡" ã¾ãŸã¯ "ãã®ä»–"
                # --- æ–°ã—ã„å¯¾è©±ãƒ•ãƒ­ãƒ¼ ---
                with st.spinner("ğŸ’– ã‚ãªãŸã®å¿ƒã®å£°ã«è€³ã‚’æ¾„ã¾ã—ã¦ã„ã¾ã™â€¦"):
                    prompt_for_consultation = f"{consultation_system_prompt}\n\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:\n{prompt}"
                    response_stream = model.generate_content(prompt_for_consultation, stream=True)
                    for chunk in response_stream:
                        if chunk.text:
                            cleaned_chunk = re.sub(r'\\(?=[\*`_])', '', chunk.text)
                            full_response += cleaned_chunk
                            placeholder.markdown(full_response + "â–Œ")

            # å¿œç­”ã®æœ€å¾Œã®æ•´å½¢ã¨è¡¨ç¤º
            final_response = re.sub(r'\\(?=[\*`_])', '', full_response)
            placeholder.markdown(final_response)
            
            # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å±¥æ­´ã«è¿½åŠ 
            st.session_state.messages.append({
                "role": "assistant", 
                "content": final_response, 
                "sources": sources, # ãƒã‚¦ãƒã‚¦æ¤œç´¢ã®å ´åˆã¯sourcesãŒå…¥ã‚Šã€ãã‚Œä»¥å¤–ã¯ç©ºã®ãƒªã‚¹ãƒˆãŒå…¥ã‚‹
                "avatar": AVATAR_IMAGE_PATH,
                "id": str(uuid.uuid4())
            })

        except Exception as e:
            st.error(f"å¤§å¤‰ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        
        st.rerun() 